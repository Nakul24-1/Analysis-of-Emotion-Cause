{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nakul24-1/Analysis-of-Emotion-Cause/blob/main/extras/robertatesting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WPjN2D_T5tj"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wMT-shJEi6d"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaConfig, RobertaModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aK6Eaq8UEsDG"
      },
      "outputs": [],
      "source": [
        "configuration = RobertaConfig()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4cO0d6DEyrS"
      },
      "outputs": [],
      "source": [
        "model = RobertaModel(configuration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "7aaTscZDFy_A",
        "outputId": "8ab1d9df-69a0-49de-e2fc-bb4f1f8f7b30"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0f00285a5c24403a73638cf8b49c48b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35b84077da7f4d7f9e6ba5ea5d73e0d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7121d25efef54c89ae629ddbed67bb5f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3a7fd7fcbeb4bc9ba960b4bb47d73e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/627M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "If you want to use `TFRobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n",
            "All model checkpoint layers were used when initializing TFRobertaForCausalLM.\n",
            "\n",
            "All the layers of TFRobertaForCausalLM were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForCausalLM for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import RobertaTokenizer, TFRobertaForCausalLM\n",
        "import tensorflow as tf\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = TFRobertaForCausalLM.from_pretrained(\"roberta-base\")\n",
        "\n",
        "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"tf\")\n",
        "outputs = model(inputs)\n",
        "logits = outputs.logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NL860gkRG9Uq",
        "outputId": "8a620216-34ff-4dce-a192-bddbd6b2ca92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 8, 50265), dtype=float32, numpy=\n",
              "array([[[35.528595  , -3.9863913 , 23.237835  , ...,  3.1884754 ,\n",
              "          5.2298965 , 12.811619  ],\n",
              "        [-1.1595345 , -3.8122017 , 12.082758  , ..., -4.4703097 ,\n",
              "         -2.3699512 ,  1.4894071 ],\n",
              "        [ 2.3193643 , -3.3484042 , 11.015812  , ...,  3.1667874 ,\n",
              "          2.2997122 ,  4.0590324 ],\n",
              "        ...,\n",
              "        [ 3.8776994 , -3.4873252 , 10.774568  , ...,  3.754785  ,\n",
              "         -0.24851859,  4.2882304 ],\n",
              "        [-0.6069057 , -4.8878274 , 10.964474  , ..., -3.008133  ,\n",
              "         -4.012106  ,  1.0598428 ],\n",
              "        [14.700357  , -5.2765093 , 25.056267  , ..., -1.299965  ,\n",
              "          0.41575372,  7.2493496 ]]], dtype=float32)>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "oVANg6ZEHOA8",
        "outputId": "12601eb0-ae0e-4e82-9744-1daa0284a537"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForMaskedLM.\n",
            "\n",
            "All the layers of TFRobertaForMaskedLM were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForMaskedLM for predictions without further training.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' good'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import RobertaTokenizer, TFRobertaForMaskedLM\n",
        "import tensorflow as tf\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = TFRobertaForMaskedLM.from_pretrained(\"roberta-base\")\n",
        "\n",
        "inputs = tokenizer(\"I am  feeling <mask> because I got a new car.\", return_tensors=\"tf\")\n",
        "logits = model(**inputs).logits\n",
        "\n",
        "# retrieve index of <mask>\n",
        "mask_token_index = tf.where(inputs.input_ids == tokenizer.mask_token_id)[0][1]\n",
        "\n",
        "predicted_token_id = tf.math.argmax(logits[0, mask_token_index], axis=-1)\n",
        "tokenizer.decode(predicted_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "QhQ5iDM-H-ZY",
        "outputId": "4a550682-0a01-4b53-84c3-090be7655f9a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-emotion.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'optimism'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import RobertaTokenizer, TFRobertaForSequenceClassification\n",
        "import tensorflow as tf\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\")\n",
        "model = TFRobertaForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\")\n",
        "\n",
        "inputs = tokenizer(\"I got a dog.\", return_tensors=\"tf\")\n",
        "\n",
        "logits = model(**inputs).logits\n",
        "\n",
        "predicted_class_id = int(tf.math.argmax(logits, axis=-1)[0])\n",
        "model.config.id2label[predicted_class_id]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "__lolu9uMtxq",
        "outputId": "f1fd37d5-e641-46a8-f2e5-10929e1c24cd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForQuestionAnswering.\n",
            "\n",
            "All the layers of TFRobertaForQuestionAnswering were initialized from the model checkpoint at ydshieh/roberta-base-squad2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForQuestionAnswering for predictions without further training.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' fear of heights'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import RobertaTokenizer, TFRobertaForQuestionAnswering\n",
        "import tensorflow as tf\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"ydshieh/roberta-base-squad2\")\n",
        "model = TFRobertaForQuestionAnswering.from_pretrained(\"ydshieh/roberta-base-squad2\")\n",
        "question, text = \"Why am I afraid?\", \"I am afraid of flying because I have fear of heights. The fear of heights is called vertigo\"\n",
        "\n",
        "inputs = tokenizer(question, text, return_tensors=\"tf\")\n",
        "outputs = model(**inputs)\n",
        "\n",
        "answer_start_index = int(tf.math.argmax(outputs.start_logits, axis=-1)[0])\n",
        "answer_end_index = int(tf.math.argmax(outputs.end_logits, axis=-1)[0])\n",
        "\n",
        "predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
        "tokenizer.decode(predict_answer_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "NdiOgPSmNglA",
        "outputId": "14b0228e-68d0-42fb-ebc7-abc61d4b364e"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-90cf4cb254f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# execute our read SQuAD function for training and validation sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mtrain_contexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_questions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_answers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_squad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'squad/train-v2.0.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mval_contexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_questions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_answers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_squad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'squad/dev-v2.0.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-90cf4cb254f8>\u001b[0m in \u001b[0;36mread_squad\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_squad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# open JSON file and load intro dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0msquad_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'squad/train-v2.0.json'"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "def read_squad(path):\n",
        "    # open JSON file and load intro dictionary\n",
        "    with open(path, 'rb') as f:\n",
        "        squad_dict = json.load(f)\n",
        "\n",
        "    # initialize lists for contexts, questions, and answers\n",
        "    contexts = []\n",
        "    questions = []\n",
        "    answers = []\n",
        "    # iterate through all data in squad data\n",
        "    for group in squad_dict['data']:\n",
        "        for passage in group['paragraphs']:\n",
        "            context = passage['context']\n",
        "            for qa in passage['qas']:\n",
        "                question = qa['question']\n",
        "                # check if we need to be extracting from 'answers' or 'plausible_answers'\n",
        "                if 'plausible_answers' in qa.keys():\n",
        "                    access = 'plausible_answers'\n",
        "                else:\n",
        "                    access = 'answers'\n",
        "                for answer in qa[access]:\n",
        "                    # append data to lists\n",
        "                    contexts.append(context)\n",
        "                    questions.append(question)\n",
        "                    answers.append(answer)\n",
        "    # return formatted data lists\n",
        "    return contexts, questions, answers\n",
        "\n",
        "# execute our read SQuAD function for training and validation sets\n",
        "train_contexts, train_questions, train_answers = read_squad('squad/train-v2.0.json')\n",
        "val_contexts, val_questions, val_answers = read_squad('squad/dev-v2.0.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOGm9pcJUAh_"
      },
      "source": [
        "# REAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-PvbghT3aHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "902ac55c-5a9c-45ec-f458-debe96194cf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.53)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "import json\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsF8NxUh3ahM"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_json(\"https://github.com/Nakul24-1/Analysis-of-Emotion-Cause/raw/main/emc_train.json\")\n",
        "df_test = pd.read_json(\"https://github.com/Nakul24-1/Analysis-of-Emotion-Cause/raw/main/emc_test.json\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['emotion'] = df_train['emotion'].apply(lambda x: x.split(\"__\")[1])\n",
        "df_test['emotion'] = df_test['emotion'].apply(lambda x: x.split(\"__\")[1])"
      ],
      "metadata": {
        "id": "KgpsVybU51eW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKz81PcR3iu9"
      },
      "outputs": [],
      "source": [
        "def read_data(context,emotions,cause,word_list):    \n",
        "  contexts = context.tolist()\n",
        "  questions = emotions.tolist()\n",
        "  answers = cause.tolist()\n",
        "  word_list = word_list.tolist()\n",
        "  key_list = [\"Text\", \"Start_Position\",\"End_Position\"]\n",
        "  res = []\n",
        "  # using list comprehension to perform as shorthand\n",
        "  n = len(answers)\n",
        "  for x in range(0,n):\n",
        "    n2 = len(answers[x])\n",
        "    text1 = \"\"\n",
        "    start_pos = []\n",
        "    end_pos = []\n",
        "    if answers[x] is not None:\n",
        "      start_pos = answers[x][0][-1]\n",
        "      end_pos = answers[x][-1][-1] + 1\n",
        "      text1=\" \".join(word_list[x][start_pos:end_pos])\n",
        "      res.append({key_list[0]: text1, key_list[1]: start_pos,key_list[2]:end_pos})\n",
        "  \n",
        "  return contexts,questions,res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lc-JtRuy4gLC"
      },
      "outputs": [],
      "source": [
        "contexts, questions, res = read_data(df_train.original_situation,df_train.emotion,df_train.annotation,df_train.tokenized_situation)\n",
        "val_contexts, val_questions, val_res = read_data(df_test.original_situation,df_test.emotion,df_test.annotation,df_test.tokenized_situation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxRB99uT8Rek",
        "outputId": "0a285a91-aa5b-4ca8-cbf3-18ee3434d35a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForQuestionAnswering: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import RobertaTokenizer,AutoTokenizer, AutoModelForQuestionAnswering\n",
        "# initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"roberta-base\")\n",
        "# tokenize\n",
        "train_encodings = tokenizer(contexts, questions, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "br-0FPEC1Nnx"
      },
      "outputs": [],
      "source": [
        "def add_token_positions(encodings, answers):\n",
        "    # initialize lists to contain the token indices of answer start/end\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "    for i in range(len(answers)):\n",
        "        # append start/end token position using char_to_token method\n",
        "        start_positions.append(encodings.word_to_tokens(i, answers[i]['Start_Position'])) #ISSUE \n",
        "        end_positions.append(encodings.word_to_tokens(i, answers[i]['End_Position']))\n",
        "\n",
        "        # if start position is None, the answer passage has been truncated\n",
        "        if start_positions[-1] is None:\n",
        "            start_positions[-1] = tokenizer.model_max_length\n",
        "        # end position cannot be found, char_to_token found space, so shift position until found\n",
        "        shift = 1\n",
        "        while end_positions[-1] is None:\n",
        "            end_positions[-1] = encodings.word_to_tokens(i, answers[i]['End_Position'] - shift)\n",
        "            shift += 1\n",
        "    # update our encodings object with the new token-based start/end positions\n",
        "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "\n",
        "# apply function to our data\n",
        "add_token_positions(train_encodings, res)\n",
        "add_token_positions(val_encodings, val_res)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_encodings['start_positions'] # val_encodings['start_positions'][1][0] is correct,, run a loop to change all"
      ],
      "metadata": {
        "id": "RDdsFua5v8e8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range(len(val_encodings['start_positions'])):\n",
        "  if val_encodings['start_positions'][x] is not tokenizer.model_max_length :\n",
        "    val_encodings['start_positions'][x]=val_encodings['start_positions'][x][0]\n",
        "  if val_encodings['end_positions'][x] is not tokenizer.model_max_length :\n",
        "    val_encodings['end_positions'][x]=val_encodings['end_positions'][x][1]\n",
        "\n",
        "for x in range(len(train_encodings['start_positions'])):\n",
        "  if (train_encodings['start_positions'][x]) is not tokenizer.model_max_length:\n",
        "    train_encodings['start_positions'][x]=train_encodings['start_positions'][x][0]\n",
        "  if (train_encodings['end_positions'][x]) is not tokenizer.model_max_length:\n",
        "    train_encodings['end_positions'][x]=train_encodings['end_positions'][x][1]"
      ],
      "metadata": {
        "id": "a-XAIiE9IsuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "mMDohyuix2OI",
        "outputId": "30af528a-f174-47f0-db14-b3b0b136aeed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>One night my children and I came home and came in through the back door. As I opened it, I saw a tall shadow in the hallway! It scared me so much, as I feared an intruder was in my home.</s></s>terrified</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "tokenizer.decode(val_encodings['input_ids'][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9DtrcQ-0Nhe",
        "outputId": "f5e0909e-f9f1-4b35-8da8-766c6861cbb5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "type(train_encodings['start_positions'][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JatP2Z4HG7zX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class EmoDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "# build datasets for both our training and validation sets\n",
        "train_dataset = EmoDataset(train_encodings)\n",
        "val_dataset = EmoDataset(val_encodings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITa3SLMAkMZw",
        "outputId": "70ef2291-04fc-466f-d4ae-756bb28da529"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 236/236 [02:52<00:00,  1.37it/s, loss=0.921]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuacry is  0.6802348164936244\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "# setup GPU/CPU\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# move model over to detected device\n",
        "model.to(device)\n",
        "# activate training mode of model\n",
        "model.train()\n",
        "# initialize adam optimizer with weight decay (reduces chance of overfitting)\n",
        "optim = AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "# initialize data loader for training data\n",
        "train_loader = DataLoader(train_dataset, batch_size= 16, shuffle=True)\n",
        "\n",
        "for epoch in range(1):\n",
        "    # set model to train mode\n",
        "    model.train()\n",
        "    # setup loop (we use tqdm for the progress bar)\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    acc = []\n",
        "    for batch in loop:\n",
        "        # initialize calculated gradients (from prev step)\n",
        "        optim.zero_grad()\n",
        "        # pull all the tensor batches required for training\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        start_positions = batch['start_positions'].to(device)\n",
        "        end_positions = batch['end_positions'].to(device)\n",
        "        # train model on batch and return outputs (incl. loss)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask,\n",
        "                        start_positions=start_positions,\n",
        "                        end_positions=end_positions)\n",
        "        \n",
        "        # extract loss\n",
        "        loss = outputs[0]\n",
        "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
        "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
        "        # calculate loss for every parameter that needs grad update\n",
        "        loss.backward()\n",
        "        # update parameters\n",
        "        optim.step()\n",
        "        acc.append(((start_pred == start_positions).sum()/len(start_pred)).item())\n",
        "        acc.append(((end_pred == end_positions).sum()/len(end_pred)).item())\n",
        "        # print relevant info to progress bar\n",
        "        loop.set_description(f'Epoch {epoch}')\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "    model_path = 'models/robertaft'+ str(epoch)\n",
        "    model.save_pretrained(model_path)\n",
        "    tokenizer.save_pretrained(model_path)\n",
        "    acc = sum(acc)/len(acc)\n",
        "    print(\"Training Accuacry is \",acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAkokkLukXqz"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "# initialize validation set data loader\n",
        "val_loader = DataLoader(val_dataset, batch_size=1)\n",
        "# initialize list to store accuracies\n",
        "acc = []\n",
        "outs = []\n",
        "ins = []\n",
        "# loop through batches\n",
        "for batch in val_loader:\n",
        "    # we don't need to calculate gradients as we're not training\n",
        "    with torch.no_grad():\n",
        "        # pull batched items from loader\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        # we will use true positions for accuracy calc\n",
        "        start_true = batch['start_positions'].to(device)\n",
        "        end_true = batch['end_positions'].to(device)\n",
        "        # make predictions\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        # pull prediction tensors out and argmax to get predicted tokens\n",
        "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
        "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
        "        for x in range(0,len(batch['input_ids'])):\n",
        "          original = input_ids[0,start_true[x] : end_true[x] + 1]\n",
        "          ins.append(tokenizer.decode(original))\n",
        "          predict_answer_tokens = input_ids[0,start_pred[x] : end_pred[x] + 1]\n",
        "          outs.append(tokenizer.decode(predict_answer_tokens))\n",
        "        # calculate accuracy for both and append to accuracy list\n",
        "        acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n",
        "        acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n",
        "# calculate average accuracy in total\n",
        "acc = sum(acc)/len(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BaXRUkX1d1p",
        "outputId": "fe9cef2f-2f8f-46bb-b20e-52ca90754030"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.48448687350835323"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "acc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"models/robertaft5\")\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"models/robertaft5\").to(device)\n",
        "\n",
        "model.eval()\n",
        "# initialize validation set data loader\n",
        "val_loader = DataLoader(val_dataset, batch_size=1)\n",
        "# initialize list to store accuracies\n",
        "acc = []\n",
        "outs = []\n",
        "ins = []\n",
        "# loop through batches\n",
        "for batch in val_loader:\n",
        "    # we don't need to calculate gradients as we're not training\n",
        "    with torch.no_grad():\n",
        "        # pull batched items from loader\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        # we will use true positions for accuracy calc\n",
        "        start_true = batch['start_positions'].to(device)\n",
        "        end_true = batch['end_positions'].to(device)\n",
        "        # make predictions\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        # pull prediction tensors out and argmax to get predicted tokens\n",
        "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
        "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
        "        for x in range(0,len(batch['input_ids'])):\n",
        "          original = input_ids[0,start_true[x] : end_true[x] + 1]\n",
        "          ins.append(tokenizer.decode(original))\n",
        "          predict_answer_tokens = input_ids[0,start_pred[x] : end_pred[x] + 1]\n",
        "          outs.append(tokenizer.decode(predict_answer_tokens))\n",
        "        # calculate accuracy for both and append to accuracy list\n",
        "        acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n",
        "        acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n",
        "# calculate average accuracy in total\n",
        "acc = sum(acc)/len(acc)"
      ],
      "metadata": {
        "id": "T4646q8mrxgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSoCwr6uT31j",
        "outputId": "1ccc6419-5db8-416d-bd9e-310cce6c171d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.49403341288782815"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ins[11:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxGWL7X45SEo",
        "outputId": "4ce42292-8256-4a1b-cb5e-9e61a4541e90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' husband has been out of town for a few weeks on business but is coming back next week',\n",
              " \" ride horses with me. After riding my mother pressured me to get on a horse bareback I wasn't comfortable riding.\",\n",
              " ' records that belong to my father before he',\n",
              " ' experience and felt very comfortable in my ability to perform the job. I was very ready for the',\n",
              " ' tattoo I was worried about pain and blood. I',\n",
              " ' husband. He has been so sweet this week. He knew I had a long day today so he bought me my favourite wine and Taco Bell!</s>',\n",
              " ' daughter how to drive, and so far, so good!</s>',\n",
              " ' first day of school for my granddaughter. She',\n",
              " ' father almost died last year']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outs[11:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDWZJCrDt6V-",
        "outputId": "9efa077f-940a-4b0a-a470-3be36800fdb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' husband has been out of town for a few weeks on business but is coming back next week',\n",
              " \" mother pressured me to get on a horse bareback I wasn't comfortable riding. She made such a big scene that I\",\n",
              " ' records that belong to my father before he passed away. Sometimes',\n",
              " ' promoted to Team',\n",
              " ' tattoo I was worried about pain and blood. I',\n",
              " ' husband. He has been so sweet this week. He knew I had a long day today so he bought me my favourite wine and Taco',\n",
              " ' teaching my daughter how to drive, and',\n",
              " \" first day of school for my granddaughter. She didn't go to preschool so I was really worried how she would like it and if she would be sad or not. Turns out she loves it and\",\n",
              " ' father almost died last year']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pd.DataFrame(list(zip(ins,outs,df_test['emotion'])),columns = ['Human Annotation','Predicted Span','Emotion'])"
      ],
      "metadata": {
        "id": "DJyJIvnede8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iou(ins,outs):\n",
        "\n",
        "  s1 = set(ins.split(' '))\n",
        "  s2 = set(outs.split(' '))\n",
        "  u = s1.union(s2)\n",
        "  inter = s1.intersection(s2)\n",
        "  iou = len(inter)/len(u)\n",
        "  return iou"
      ],
      "metadata": {
        "id": "qsw8pz9lgRJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result['IOU'] = result.apply(lambda row : iou(row['Human Annotation'],\n",
        "                     row['Predicted Span']), axis = 1)"
      ],
      "metadata": {
        "id": "OeVScRnvgREG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "RhAClbA5gVzw",
        "outputId": "670bbb2b-d12a-4c29-9240-962aaa096a34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      Human Annotation  \\\n",
              "0           rendition of a play. But my friend got it.   \n",
              "1     saw a tall shadow in the hallway! It scared m...   \n",
              "2               slipped and fell on the wet floor as I   \n",
              "3     supervisor. It seemed suspicious so I pretty ...   \n",
              "4                  't give a homeless man any money. I   \n",
              "..                                                 ...   \n",
              "833                       saw a homeless guy the other   \n",
              "834   learn how different my two kids' personalitie...   \n",
              "835   wife surpises me with a picture of our future...   \n",
              "836                              shouted to my mom</s>   \n",
              "837                   poop. It makes me feel sick!</s>   \n",
              "\n",
              "                                        Predicted Span      Emotion       IOU  \n",
              "0                                        friend got it      jealous  0.272727  \n",
              "1                            shadow in the hallway! It    terrified  0.315789  \n",
              "2               slipped and fell on the wet floor as I  embarrassed  1.000000  \n",
              "3                             weird questions about my     faithful  0.043478  \n",
              "4                              give a homeless man any       guilty  0.555556  \n",
              "..                                                 ...          ...       ...  \n",
              "833                             homeless guy the other     grateful  0.714286  \n",
              "834      different my two kids' personalities could be    surprised  0.800000  \n",
              "835   wife surpises me with a picture of our future...       joyful  1.000000  \n",
              "836                              shouted to my mom</s>       guilty  1.000000  \n",
              "837   dog that lives near us and his owner never pi...    disgusted  0.166667  \n",
              "\n",
              "[838 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b7fcc4d3-4ad8-4f1e-9c30-7bfe0c6ae2e1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Human Annotation</th>\n",
              "      <th>Predicted Span</th>\n",
              "      <th>Emotion</th>\n",
              "      <th>IOU</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rendition of a play. But my friend got it.</td>\n",
              "      <td>friend got it</td>\n",
              "      <td>jealous</td>\n",
              "      <td>0.272727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>saw a tall shadow in the hallway! It scared m...</td>\n",
              "      <td>shadow in the hallway! It</td>\n",
              "      <td>terrified</td>\n",
              "      <td>0.315789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>slipped and fell on the wet floor as I</td>\n",
              "      <td>slipped and fell on the wet floor as I</td>\n",
              "      <td>embarrassed</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>supervisor. It seemed suspicious so I pretty ...</td>\n",
              "      <td>weird questions about my</td>\n",
              "      <td>faithful</td>\n",
              "      <td>0.043478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>'t give a homeless man any money. I</td>\n",
              "      <td>give a homeless man any</td>\n",
              "      <td>guilty</td>\n",
              "      <td>0.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>833</th>\n",
              "      <td>saw a homeless guy the other</td>\n",
              "      <td>homeless guy the other</td>\n",
              "      <td>grateful</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>834</th>\n",
              "      <td>learn how different my two kids' personalitie...</td>\n",
              "      <td>different my two kids' personalities could be</td>\n",
              "      <td>surprised</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>835</th>\n",
              "      <td>wife surpises me with a picture of our future...</td>\n",
              "      <td>wife surpises me with a picture of our future...</td>\n",
              "      <td>joyful</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>836</th>\n",
              "      <td>shouted to my mom&lt;/s&gt;</td>\n",
              "      <td>shouted to my mom&lt;/s&gt;</td>\n",
              "      <td>guilty</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>837</th>\n",
              "      <td>poop. It makes me feel sick!&lt;/s&gt;</td>\n",
              "      <td>dog that lives near us and his owner never pi...</td>\n",
              "      <td>disgusted</td>\n",
              "      <td>0.166667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>838 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7fcc4d3-4ad8-4f1e-9c30-7bfe0c6ae2e1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b7fcc4d3-4ad8-4f1e-9c30-7bfe0c6ae2e1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b7fcc4d3-4ad8-4f1e-9c30-7bfe0c6ae2e1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.mean(result[\"IOU\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Vyh2xeQl5b1",
        "outputId": "1b7817e6-a30f-45b6-8b7d-dcc82ded4011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6288723614823174"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hugging face upload"
      ],
      "metadata": {
        "id": "mX-E4Y5G2VAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630,
          "referenced_widgets": [
            "3ffbae14c06a454da55482f6d0a68103",
            "d2deff4b61874c159ced57e186b9159a",
            "3aef0e382bfb420c950d332f863ef2da",
            "921af29205ed48c9a4481de6b278e9f9",
            "255495588e0345ebae888234ade42a41",
            "3c2e9ed0e9af43cf9dfbc000cf830166",
            "20c527e7ea7e49c6bb8ea9f252a67a57",
            "0897a2a1078c4774aa52bcebc550bcef",
            "06c6ace55120436db63d34d4da8d83d5",
            "b3ef5c4fb399428f9fb3810db6665438",
            "a79afde87a9b450ab37c6b9c10c28774",
            "b6295865c75b4ba7b0cd5f1118133a4d",
            "110feddec56947eb9527cc47f62da1cf",
            "27006b892dee44a885ba7194e91e229b",
            "49b4749c240e4bbfa7bfc9fc9f7a8f19",
            "f120fb52503840a2ab8cc501521d4471",
            "e97c48b0a4354bfcadebd5d0dbc2c4d8"
          ]
        },
        "id": "BuKSGCd5yDsu",
        "outputId": "58eaa362-2c06-4677-f260-1a78e7909529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Login successful\n",
            "Your token has been saved to /root/.huggingface/token\n",
            "\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n",
            "\n",
            "git config --global credential.helper store\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(\"Nakul24/RoBERTa-emotion-extraction\")\n",
        "tokenizer.push_to_hub(\"Nakul24/RoBERTa-emotion-extraction\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278,
          "referenced_widgets": [
            "05adda3ad12a4d71973140ba2af3b664",
            "aa6416d16fee42a5973de3caf91d2a92",
            "ecd6a2b5b06440d3ba4973b8eb49ed1a",
            "55062e2d40904e4e9fe35b22f391d4ef",
            "0074190b6914439bbb63fdd01d180384",
            "3e7f78ede8d047e0b9607c73cd4cd728",
            "98dee3541c7c48e198cb16bbeb872b6e",
            "24dae12f074e47348304a6bdd8753384",
            "b80daa7bf7f54e94a8ddbc932ac1844d",
            "8c9ffe69c7d2489cb09f516a6fee003a",
            "a00b9be70da948d5876a6c034b21fd6f"
          ]
        },
        "id": "uS8_CWBB2Y8y",
        "outputId": "d82b6376-cb1a-414b-8ba7-5b727dbae3c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/huggingface_hub/utils/_deprecation.py:43: FutureWarning: Pass token='RoBERTa-emotion-extraction' as keyword args. From version 0.7 passing these as positional arguments will result in an error\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/huggingface_hub/hf_api.py:599: FutureWarning: `create_repo` now takes `token` as an optional positional argument. Be sure to adapt your code!\n",
            "  FutureWarning,\n",
            "Cloning https://huggingface.co/Nakul24/RoBERTa-emotion-extraction into local empty directory.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 3.34k/473M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05adda3ad12a4d71973140ba2af3b664"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "To https://huggingface.co/Nakul24/RoBERTa-emotion-extraction\n",
            "   ae8ee73..fed0819  main -> main\n",
            "\n",
            "To https://huggingface.co/Nakul24/RoBERTa-emotion-extraction\n",
            "   fed0819..43abab0  main -> main\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://huggingface.co/Nakul24/RoBERTa-emotion-extraction/commit/43abab03b92f84ca618992ea26084d641b294c5e'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL 3 - \n",
        "MODEL 4 - 0.6283977284141783\n",
        "MODEL 5 - 0.6288723614823174\n",
        "MODEL 2 - "
      ],
      "metadata": {
        "id": "zceayWAomAAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "M_PB4T7cpFLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sNC0XB3ggQPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "C4ZXuRCqgQGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXTRAS"
      ],
      "metadata": {
        "id": "_VEBTHxWo_lH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'models/robertaft'\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4heh5q9MbyE",
        "outputId": "e14365e6-abe3-4b4f-a7c8-3e88a022d4be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('models/robertaft/tokenizer_config.json',\n",
              " 'models/robertaft/special_tokens_map.json',\n",
              " 'models/robertaft/vocab.json',\n",
              " 'models/robertaft/merges.txt',\n",
              " 'models/robertaft/added_tokens.json',\n",
              " 'models/robertaft/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"models/robertaft\")\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"models/robertaft\").to(device)"
      ],
      "metadata": {
        "id": "FpSmTr5XTEyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfAWacQ0RD3t",
        "outputId": "9db4b83b-caf2-4711-861f-eed442f4e911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5155, device='cuda:0', grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghtiZuUKBGGD",
        "outputId": "229c11f2-86ce-4cfe-f95c-cb88b2de891b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T/F\tstart\tend\n",
            "\n",
            "true\t16\t24\n",
            "pred\t4\t18\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"T/F\\tstart\\tend\\n\")\n",
        "for i in range(len(start_true)):\n",
        "    print(f\"true\\t{start_true[i]}\\t{end_true[i]}\\n\"\n",
        "          f\"pred\\t{start_pred[i]}\\t{end_pred[i]}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKx-iuJqEpQz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b8836e63-20ce-4498-f514-508ebd6ef6ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' scratched by the cat, I'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "question, text = \"__angry__\", \"The table was scratched by the cat, I'm very upset and feel like killing it\"\n",
        "\n",
        "inputs = tokenizer(question, text, return_tensors=\"pt\")\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "answer_start_index = outputs.start_logits.argmax()\n",
        "answer_end_index = outputs.end_logits.argmax()\n",
        "\n",
        "predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
        "tokenizer.decode(predict_answer_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95XcXdO-FZFQ"
      },
      "outputs": [],
      "source": [
        "print (device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bynq5vOHIJw5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bj6PAiGKImSl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "c1793407-ff5e-4ef6-d6ba-8a39f40c6139"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8c50d704ed75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/robertaft3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForQuestionAnswering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/robertaft3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'AutoTokenizer' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"models/robertaft3\")\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"models/robertaft3\")\n",
        "\n",
        "question, text = \"happy\", \"I'm elated by the fact that I got a promotion\"\n",
        "\n",
        "\n",
        "inputs = tokenizer(text,question, return_tensors=\"pt\",truncation=True, padding=True)\n",
        "with torch.no_grad():\n",
        "  outputs = model(**inputs)\n",
        "\n",
        "answer_start_index = outputs.start_logits.argmax()\n",
        "answer_end_index = outputs.end_logits.argmax()\n",
        "\n",
        "\n",
        "predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
        "tokenizer.decode(predict_answer_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgrNrP69JJD9",
        "outputId": "22ce61ef-1d0e-45c0-8ea8-afbc3540d16a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "answer_start_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YV7ZU8iUT185",
        "outputId": "d5b866ff-10de-4bb9-efba-eda3ea7418c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(4)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "answer_end_index + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UD-hdvjgT5bK",
        "outputId": "e708e31e-91f5-4e7b-f826-578415f7a299"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<s>Ramesh and Suresh along with Ganesh told me that I am rich</s></s>__happy__</s>'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode(inputs.input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58e4kFlMUDRb"
      },
      "outputs": [],
      "source": [
        "start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
        "end_pred = torch.argmax(outputs['end_logits'], dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymTRnP_hWSqW",
        "outputId": "1d80ccf3-2ea0-4d61-f4db-1a38ba116cc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([2])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "start_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxD3jn7IWUqL",
        "outputId": "c4474f43-d70d-43a8-ae7b-a7049f6a4fe8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([4])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "end_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02ZoOCMAWXua"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(contexts, questions, truncation=True, padding=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "8WPjN2D_T5tj",
        "_VEBTHxWo_lH"
      ],
      "name": "robertatesting.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3ffbae14c06a454da55482f6d0a68103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2deff4b61874c159ced57e186b9159a",
              "IPY_MODEL_3aef0e382bfb420c950d332f863ef2da",
              "IPY_MODEL_921af29205ed48c9a4481de6b278e9f9",
              "IPY_MODEL_255495588e0345ebae888234ade42a41",
              "IPY_MODEL_3c2e9ed0e9af43cf9dfbc000cf830166"
            ],
            "layout": "IPY_MODEL_20c527e7ea7e49c6bb8ea9f252a67a57"
          }
        },
        "d2deff4b61874c159ced57e186b9159a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0897a2a1078c4774aa52bcebc550bcef",
            "placeholder": "​",
            "style": "IPY_MODEL_06c6ace55120436db63d34d4da8d83d5",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "3aef0e382bfb420c950d332f863ef2da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_b3ef5c4fb399428f9fb3810db6665438",
            "placeholder": "​",
            "style": "IPY_MODEL_a79afde87a9b450ab37c6b9c10c28774",
            "value": ""
          }
        },
        "921af29205ed48c9a4481de6b278e9f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_b6295865c75b4ba7b0cd5f1118133a4d",
            "style": "IPY_MODEL_110feddec56947eb9527cc47f62da1cf",
            "tooltip": ""
          }
        },
        "255495588e0345ebae888234ade42a41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27006b892dee44a885ba7194e91e229b",
            "placeholder": "​",
            "style": "IPY_MODEL_49b4749c240e4bbfa7bfc9fc9f7a8f19",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. <br> <i>Logging in with your username and password is deprecated and\nwon't be possible anymore in the near future. You can still use them for now by\nclicking below.</i> </center>"
          }
        },
        "3c2e9ed0e9af43cf9dfbc000cf830166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Use password",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_f120fb52503840a2ab8cc501521d4471",
            "style": "IPY_MODEL_e97c48b0a4354bfcadebd5d0dbc2c4d8",
            "tooltip": ""
          }
        },
        "20c527e7ea7e49c6bb8ea9f252a67a57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "0897a2a1078c4774aa52bcebc550bcef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06c6ace55120436db63d34d4da8d83d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3ef5c4fb399428f9fb3810db6665438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a79afde87a9b450ab37c6b9c10c28774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6295865c75b4ba7b0cd5f1118133a4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "110feddec56947eb9527cc47f62da1cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "27006b892dee44a885ba7194e91e229b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49b4749c240e4bbfa7bfc9fc9f7a8f19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f120fb52503840a2ab8cc501521d4471": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e97c48b0a4354bfcadebd5d0dbc2c4d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "05adda3ad12a4d71973140ba2af3b664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa6416d16fee42a5973de3caf91d2a92",
              "IPY_MODEL_ecd6a2b5b06440d3ba4973b8eb49ed1a",
              "IPY_MODEL_55062e2d40904e4e9fe35b22f391d4ef"
            ],
            "layout": "IPY_MODEL_0074190b6914439bbb63fdd01d180384"
          }
        },
        "aa6416d16fee42a5973de3caf91d2a92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e7f78ede8d047e0b9607c73cd4cd728",
            "placeholder": "​",
            "style": "IPY_MODEL_98dee3541c7c48e198cb16bbeb872b6e",
            "value": "Upload file pytorch_model.bin: 100%"
          }
        },
        "ecd6a2b5b06440d3ba4973b8eb49ed1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24dae12f074e47348304a6bdd8753384",
            "max": 496297393,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b80daa7bf7f54e94a8ddbc932ac1844d",
            "value": 496297393
          }
        },
        "55062e2d40904e4e9fe35b22f391d4ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c9ffe69c7d2489cb09f516a6fee003a",
            "placeholder": "​",
            "style": "IPY_MODEL_a00b9be70da948d5876a6c034b21fd6f",
            "value": " 473M/473M [08:11&lt;00:00, 716kB/s]"
          }
        },
        "0074190b6914439bbb63fdd01d180384": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e7f78ede8d047e0b9607c73cd4cd728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98dee3541c7c48e198cb16bbeb872b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24dae12f074e47348304a6bdd8753384": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b80daa7bf7f54e94a8ddbc932ac1844d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c9ffe69c7d2489cb09f516a6fee003a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a00b9be70da948d5876a6c034b21fd6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}